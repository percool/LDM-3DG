{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed67a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import BondType, HybridizationType\n",
    "# from torch_scatter import scatter\n",
    "\n",
    "\n",
    "# general tools\n",
    "import numpy as np\n",
    "# RDkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "# Pytorch and Pytorch Geometric\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c285f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load the Data \"\"\"\n",
    "\n",
    "SMILE_PATH = './sample_smiles.pt'\n",
    "LATENT_PATH = './sample_z.pt'\n",
    "\n",
    "# smile is a list of str (e.g. 'Cn1ncc2c3ncncc3n(CC3CC4OC3Cc3oncc34)c21')\n",
    "# len of smile : 100000\n",
    "smile = torch.load(SMILE_PATH)\n",
    "\n",
    "# [:250] in latent vector is corresponding to 2D part\n",
    "# shape = [100, 1000, 500]\n",
    "latent = torch.load(LATENT_PATH)\n",
    "emb2d = latent.reshape(-1,500)[:,:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac4234",
   "metadata": {},
   "source": [
    "## Feature Encoding\n",
    "From this on, the credits of the code all goes to: https://www.blopig.com/blog/2022/02/how-to-turn-a-smiles-string-into-a-molecular-graph-for-pytorch-geometric/\n",
    "This is NOT my work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d925423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, permitted_list):\n",
    "    \"\"\"\n",
    "    Maps input elements x which are not in the permitted list to the last element\n",
    "    of the permitted list.\n",
    "    \"\"\"\n",
    "\n",
    "    if x not in permitted_list:\n",
    "        x = permitted_list[-1]\n",
    "\n",
    "    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n",
    "\n",
    "    return binary_encoding\n",
    "\n",
    "def get_atom_features(atom, \n",
    "                      use_chirality = True, \n",
    "                      hydrogens_implicit = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    # define list of permitted atoms\n",
    "    \n",
    "    permitted_list_of_atoms =  ['C','N','O','S','F','Si','P','Cl','Br','Mg','Na','Ca','Fe','As','Al','I', 'B','V','K','Tl','Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn', 'Li','Ge','Cu','Au','Ni','Cd','In','Mn','Zr','Cr','Pt','Hg','Pb','Unknown']\n",
    "    \n",
    "    if hydrogens_implicit == False:\n",
    "        permitted_list_of_atoms = ['H'] + permitted_list_of_atoms\n",
    "    \n",
    "    # compute atom features\n",
    "    \n",
    "    atom_type_enc = one_hot_encoding(str(atom.GetSymbol()), permitted_list_of_atoms)\n",
    "    \n",
    "    n_heavy_neighbors_enc = one_hot_encoding(int(atom.GetDegree()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "    \n",
    "    formal_charge_enc = one_hot_encoding(int(atom.GetFormalCharge()), [-3, -2, -1, 0, 1, 2, 3, \"Extreme\"])\n",
    "    \n",
    "    hybridisation_type_enc = one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n",
    "    \n",
    "    is_in_a_ring_enc = [int(atom.IsInRing())]\n",
    "    \n",
    "    is_aromatic_enc = [int(atom.GetIsAromatic())]\n",
    "    \n",
    "    atomic_mass_scaled = [float((atom.GetMass() - 10.812)/116.092)]\n",
    "    \n",
    "    vdw_radius_scaled = [float((Chem.GetPeriodicTable().GetRvdw(atom.GetAtomicNum()) - 1.5)/0.6)]\n",
    "    \n",
    "    covalent_radius_scaled = [float((Chem.GetPeriodicTable().GetRcovalent(atom.GetAtomicNum()) - 0.64)/0.76)]\n",
    "\n",
    "    atom_feature_vector = atom_type_enc + n_heavy_neighbors_enc + formal_charge_enc + hybridisation_type_enc + is_in_a_ring_enc + is_aromatic_enc + atomic_mass_scaled + vdw_radius_scaled + covalent_radius_scaled\n",
    "                                    \n",
    "    if use_chirality == True:\n",
    "        chirality_type_enc = one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n",
    "        atom_feature_vector += chirality_type_enc\n",
    "    \n",
    "    if hydrogens_implicit == True:\n",
    "        n_hydrogens_enc = one_hot_encoding(int(atom.GetTotalNumHs()), [0, 1, 2, 3, 4, \"MoreThanFour\"])\n",
    "        atom_feature_vector += n_hydrogens_enc\n",
    "\n",
    "    return np.array(atom_feature_vector)\n",
    "\n",
    "def get_bond_features(bond, \n",
    "                      use_stereochemistry = True):\n",
    "    \"\"\"\n",
    "    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n",
    "\n",
    "    bond_type_enc = one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)\n",
    "    \n",
    "    bond_is_conj_enc = [int(bond.GetIsConjugated())]\n",
    "    \n",
    "    bond_is_in_ring_enc = [int(bond.IsInRing())]\n",
    "    \n",
    "    bond_feature_vector = bond_type_enc + bond_is_conj_enc + bond_is_in_ring_enc\n",
    "    \n",
    "    if use_stereochemistry == True:\n",
    "        stereo_type_enc = one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n",
    "        bond_feature_vector += stereo_type_enc\n",
    "\n",
    "    return np.array(bond_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7efa347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pytorch_geometric_graph_data_list_from_smiles_and_labels(x_smiles, y):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    \n",
    "    x_smiles = [smiles_1, smiles_2, ....] ... a list of SMILES strings\n",
    "    y = [y_1, y_2, ...] ... a list of numerial labels for the SMILES strings (such as associated pKi values)\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    data_list = [G_1, G_2, ...] ... a list of torch_geometric.data.Data objects which represent labeled molecular graphs that can readily be used for machine learning\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for (smiles, y_val) in zip(x_smiles, y):\n",
    "        \n",
    "        # convert SMILES to RDKit mol object\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        # get feature dimensions\n",
    "        n_nodes = mol.GetNumAtoms()\n",
    "        n_edges = 2*mol.GetNumBonds()\n",
    "        unrelated_smiles = \"O=O\"\n",
    "        unrelated_mol = Chem.MolFromSmiles(unrelated_smiles)\n",
    "        n_node_features = len(get_atom_features(unrelated_mol.GetAtomWithIdx(0)))\n",
    "        n_edge_features = len(get_bond_features(unrelated_mol.GetBondBetweenAtoms(0,1)))\n",
    "\n",
    "        # construct node feature matrix X of shape (n_nodes, n_node_features)\n",
    "        X = np.zeros((n_nodes, n_node_features))\n",
    "\n",
    "        for atom in mol.GetAtoms():\n",
    "            X[atom.GetIdx(), :] = get_atom_features(atom)\n",
    "            \n",
    "        X = torch.tensor(X, dtype = torch.float)\n",
    "        \n",
    "        # construct edge index array E of shape (2, n_edges)\n",
    "        (rows, cols) = np.nonzero(GetAdjacencyMatrix(mol))\n",
    "        torch_rows = torch.from_numpy(rows.astype(np.int64)).to(torch.long)\n",
    "        torch_cols = torch.from_numpy(cols.astype(np.int64)).to(torch.long)\n",
    "        E = torch.stack([torch_rows, torch_cols], dim = 0)\n",
    "        \n",
    "        # construct edge feature array EF of shape (n_edges, n_edge_features)\n",
    "        EF = np.zeros((n_edges, n_edge_features))\n",
    "        \n",
    "        for (k, (i,j)) in enumerate(zip(rows, cols)):\n",
    "            \n",
    "            EF[k] = get_bond_features(mol.GetBondBetweenAtoms(int(i),int(j)))\n",
    "        \n",
    "        EF = torch.tensor(EF, dtype = torch.float)\n",
    "        \n",
    "        # construct label tensor\n",
    "#         y_tensor = torch.tensor(np.array([y_val]), dtype = torch.float)\n",
    "        y_tensor = y_val\n",
    "        \n",
    "        # construct Pytorch Geometric data object and append to data list\n",
    "        data_list.append(Data(x = X, edge_index = E, edge_attr = EF, y = y_tensor))\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b87374c",
   "metadata": {},
   "source": [
    "## GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0c4a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "class GCNRegression(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, output_channels):\n",
    "        super(GCNRegression, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, output_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7936c3",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e5f8f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09767dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[25, 79], edge_index=[2, 60], edge_attr=[60, 10], y=[250])\n"
     ]
    }
   ],
   "source": [
    "# create list of molecular graph objects from list of SMILES x_smiles and list of labels y\n",
    "# x, edge_index, edge_attr, y\n",
    "data_list = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(smile, emb2d)\n",
    "\n",
    "print(data_list[0])\n",
    "print(data_list[1].x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5f30fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/user/chenyus0609/.conda/envs/SLR/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data, DataLoader\n",
    "def custom_collate(batch):  \n",
    "    # Assuming all data objects have the same attributes and properties\n",
    "    keys = batch[0].keys\n",
    "    batched_data = Data.from_data_list(batch)\n",
    "    \n",
    "    return batched_data\n",
    "\n",
    "# create dataloader for training\n",
    "dataloader = DataLoader(dataset = data_list, batch_size = 10000, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e158e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create Model \"\"\"\n",
    "\n",
    "num_features = 79\n",
    "\n",
    "# Define model\n",
    "gnn_model = GCNRegression(num_features, hidden_channels=16, output_channels=250)\n",
    "\n",
    "optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee25d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 250])\n"
     ]
    }
   ],
   "source": [
    "# test model: 1 instance\n",
    "batch = torch.tensor(np.zeros(data_list[1].x.shape[0]), dtype=torch.long)\n",
    "o = gnn_model(data_list[1].x, data_list[1].edge_index, batch)\n",
    "print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e82849c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/10 [00:00<?, ?batch/s]/tmp/job.10333674/ipykernel_188945/1337025016.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss_function_value = loss_function(output, torch.tensor(batch.y.view(-1, 250), dtype=torch.float32))\n",
      "Epoch 1/10:  10%|█         | 1/10 [00:02<00:19,  2.12s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.721059799194336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  20%|██        | 2/10 [00:04<00:16,  2.10s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.709997177124023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  30%|███       | 3/10 [00:06<00:14,  2.07s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.712749481201172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  40%|████      | 4/10 [00:08<00:12,  2.15s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.713510513305664.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  50%|█████     | 5/10 [00:11<00:11,  2.34s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.711008071899414.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  60%|██████    | 6/10 [00:13<00:09,  2.34s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.709936141967773.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  70%|███████   | 7/10 [00:15<00:06,  2.27s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.709157943725586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  80%|████████  | 8/10 [00:17<00:04,  2.23s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.71107292175293.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  90%|█████████ | 9/10 [00:19<00:02,  2.21s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.712221145629883.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 10/10 [00:22<00:00,  2.21s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1: 30.706851959228516.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  10%|█         | 1/10 [00:02<00:19,  2.15s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.71082305908203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  20%|██        | 2/10 [00:04<00:16,  2.09s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.705904006958008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  30%|███       | 3/10 [00:06<00:14,  2.08s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.709890365600586.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  40%|████      | 4/10 [00:08<00:12,  2.11s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.710664749145508.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  50%|█████     | 5/10 [00:10<00:10,  2.12s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.70797348022461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  60%|██████    | 6/10 [00:12<00:08,  2.12s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.706768035888672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  70%|███████   | 7/10 [00:14<00:06,  2.13s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.7060546875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  80%|████████  | 8/10 [00:16<00:04,  2.14s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.7082462310791.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  90%|█████████ | 9/10 [00:19<00:02,  2.14s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.70983123779297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 10/10 [00:21<00:00,  2.14s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 2: 30.704946517944336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  10%|█         | 1/10 [00:03<00:29,  3.31s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.709426879882812.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  20%|██        | 2/10 [00:05<00:21,  2.75s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.70493507385254.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  30%|███       | 3/10 [00:08<00:20,  2.94s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.70913314819336.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  40%|████      | 4/10 [00:10<00:15,  2.58s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.709917068481445.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  50%|█████     | 5/10 [00:12<00:12,  2.41s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.707286834716797.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  60%|██████    | 6/10 [00:15<00:09,  2.31s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.706239700317383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  70%|███████   | 7/10 [00:17<00:06,  2.23s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.705705642700195.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  80%|████████  | 8/10 [00:19<00:04,  2.20s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.708003997802734.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  90%|█████████ | 9/10 [00:21<00:02,  2.17s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.709632873535156.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 10/10 [00:23<00:00,  2.35s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 3: 30.70476722717285.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  10%|█         | 1/10 [00:02<00:18,  2.03s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.709274291992188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  20%|██        | 2/10 [00:04<00:16,  2.04s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.70480728149414.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  30%|███       | 3/10 [00:06<00:14,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.709020614624023.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  40%|████      | 4/10 [00:08<00:12,  2.03s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.70981788635254.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  50%|█████     | 5/10 [00:10<00:10,  2.03s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.707197189331055.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  60%|██████    | 6/10 [00:12<00:08,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.706157684326172.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  70%|███████   | 7/10 [00:14<00:06,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.70562171936035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  80%|████████  | 8/10 [00:16<00:04,  2.03s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.70792007446289.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  90%|█████████ | 9/10 [00:18<00:02,  2.26s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.709543228149414.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 10/10 [00:21<00:00,  2.10s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 4: 30.70467185974121.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  10%|█         | 1/10 [00:02<00:18,  2.05s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.709177017211914.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  20%|██        | 2/10 [00:04<00:19,  2.42s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.704713821411133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  30%|███       | 3/10 [00:06<00:15,  2.24s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.70893096923828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  40%|████      | 4/10 [00:09<00:13,  2.30s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.709733963012695.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  50%|█████     | 5/10 [00:11<00:10,  2.19s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.707109451293945.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  60%|██████    | 6/10 [00:13<00:08,  2.14s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.706073760986328.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  70%|███████   | 7/10 [00:15<00:06,  2.13s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.705541610717773.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  80%|████████  | 8/10 [00:17<00:04,  2.13s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.707839965820312.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  90%|█████████ | 9/10 [00:19<00:02,  2.13s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.70947265625.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 10/10 [00:21<00:00,  2.17s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 5: 30.70461082458496.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  10%|█         | 1/10 [00:02<00:18,  2.11s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.70911407470703.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  20%|██        | 2/10 [00:04<00:16,  2.11s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.70465850830078.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  30%|███       | 3/10 [00:06<00:14,  2.11s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.708879470825195.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  40%|████      | 4/10 [00:08<00:12,  2.11s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.709686279296875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  50%|█████     | 5/10 [00:10<00:10,  2.08s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.70707130432129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  60%|██████    | 6/10 [00:12<00:08,  2.06s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.706035614013672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  70%|███████   | 7/10 [00:14<00:06,  2.04s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.705507278442383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  80%|████████  | 8/10 [00:17<00:04,  2.20s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.707805633544922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  90%|█████████ | 9/10 [00:19<00:02,  2.14s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.709440231323242.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 10/10 [00:21<00:00,  2.10s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 6: 30.704578399658203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  10%|█         | 1/10 [00:02<00:18,  2.00s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.70908546447754.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  20%|██        | 2/10 [00:04<00:16,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.704633712768555.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  30%|███       | 3/10 [00:06<00:14,  2.01s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.70885467529297.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  40%|████      | 4/10 [00:08<00:12,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.709657669067383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  50%|█████     | 5/10 [00:10<00:10,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.707042694091797.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  60%|██████    | 6/10 [00:12<00:08,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.706016540527344.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  70%|███████   | 7/10 [00:14<00:06,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.705488204956055.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  80%|████████  | 8/10 [00:16<00:04,  2.03s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.707796096801758.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  90%|█████████ | 9/10 [00:18<00:02,  2.03s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.709423065185547.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 10/10 [00:20<00:00,  2.03s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 7: 30.70456314086914.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  10%|█         | 1/10 [00:02<00:18,  2.01s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.70906639099121.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  20%|██        | 2/10 [00:04<00:16,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.704614639282227.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  30%|███       | 3/10 [00:06<00:14,  2.00s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.70883560180664.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  40%|████      | 4/10 [00:08<00:12,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.709644317626953.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  50%|█████     | 5/10 [00:10<00:10,  2.01s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.707027435302734.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  60%|██████    | 6/10 [00:12<00:08,  2.17s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.70599365234375.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  70%|███████   | 7/10 [00:14<00:06,  2.11s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.70546531677246.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  80%|████████  | 8/10 [00:16<00:04,  2.08s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.707773208618164.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  90%|█████████ | 9/10 [00:18<00:02,  2.05s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.70940399169922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 10/10 [00:20<00:00,  2.05s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 8: 30.704544067382812.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  10%|█         | 1/10 [00:02<00:18,  2.00s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.709049224853516.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  20%|██        | 2/10 [00:04<00:16,  2.01s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.7045955657959.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  30%|███       | 3/10 [00:06<00:14,  2.00s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.708816528320312.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  40%|████      | 4/10 [00:08<00:12,  2.01s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.709623336791992.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  50%|█████     | 5/10 [00:10<00:10,  2.01s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.707008361816406.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  60%|██████    | 6/10 [00:12<00:08,  2.00s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.705974578857422.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  70%|███████   | 7/10 [00:14<00:06,  2.01s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.7054500579834.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  80%|████████  | 8/10 [00:16<00:04,  2.03s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.707754135131836.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  90%|█████████ | 9/10 [00:18<00:02,  2.02s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.709392547607422.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 10/10 [00:20<00:00,  2.03s/batch, loss=30.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 9: 30.704530715942383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  10%|█         | 1/10 [00:02<00:19,  2.13s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.709033966064453.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  20%|██        | 2/10 [00:04<00:19,  2.43s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.704586029052734.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  30%|███       | 3/10 [00:06<00:15,  2.28s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.708803176879883.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  40%|████      | 4/10 [00:08<00:13,  2.22s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.709611892700195.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  50%|█████     | 5/10 [00:11<00:10,  2.18s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.706995010375977.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  60%|██████    | 6/10 [00:13<00:08,  2.16s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.705970764160156.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  70%|███████   | 7/10 [00:15<00:06,  2.14s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.705440521240234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  80%|████████  | 8/10 [00:17<00:04,  2.14s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.707746505737305.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  90%|█████████ | 9/10 [00:19<00:02,  2.13s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.709379196166992.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 10/10 [00:21<00:00,  2.17s/batch, loss=30.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 10: 30.70452117919922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gnn_model.to(device)\n",
    "\n",
    "# loop over 10 training epochs\n",
    "for epoch in range(10):\n",
    "\n",
    "    # set model to training mode\n",
    "    gnn_model.train()\n",
    "\n",
    "    # initialize tqdm for progress visualization\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f'Epoch {epoch + 1}/10', unit='batch')\n",
    "    # loop over minibatches for training\n",
    "    for k, batch in pbar:\n",
    "        \n",
    "        # compute current value of loss function via forward pass\n",
    "        b = batch.batch\n",
    "        output = gnn_model(batch.x, batch.edge_index, b)\n",
    "        loss_function_value = loss_function(output, torch.tensor(batch.y.view(-1, 250), dtype=torch.float32))\n",
    "\n",
    "        # set past gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute current gradient via backward pass\n",
    "        loss_function_value.backward()\n",
    "\n",
    "        # update model weights using gradient and optimisation method\n",
    "        optimizer.step()\n",
    "\n",
    "        # update progress bar description\n",
    "        pbar.set_postfix(loss=loss_function_value.item())\n",
    "        \n",
    "        print(f'Training loss at epoch {epoch+1}: {loss_function_value}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22016e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "TIME = '05_06__17_53'\n",
    "torch.save(gnn_model.state_dict(), f'./gnn_model_weights_{TIME}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "244838f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Inference all the instances\n",
    "gnn_model.eval()\n",
    "emb_g2d = []\n",
    "\n",
    "for item in data_list:\n",
    "    b = torch.tensor(np.zeros(item.x.shape[0]), dtype=torch.long)\n",
    "    emb_g2d.append(gnn_model(item.x, item.edge_index, b))\n",
    "\n",
    "print(len(emb_g2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83f9b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(emb_g2d, f\"./emb_g2d_{TIME}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-SLR] *",
   "language": "python",
   "name": "conda-env-.conda-SLR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
